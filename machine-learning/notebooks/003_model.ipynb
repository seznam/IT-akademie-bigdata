{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f12a4b-cd28-4731-af17-29aba409d35a",
   "metadata": {
    "id": "63f12a4b-cd28-4731-af17-29aba409d35a"
   },
   "source": [
    " # 3. Trénink modelu predikce prokliku\n",
    "V následujícím notebooku se pokusíme natrénovat model predikce prokliku pomocí knihovny [vowpal wabbit](https://vowpalwabbit.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3617d78-5126-4b3e-b00b-efd0ebfc29d9",
   "metadata": {
    "id": "b3617d78-5126-4b3e-b00b-efd0ebfc29d9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_DIR = \"/content/gdrive/MyDrive/itacademy2022\"\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    BASE_DIR = \"..\"\n",
    "\n",
    "MIND_DATA_SOURCE_DIR = \"tmp/mind\"\n",
    "ORIGINAL_TRAIN_INPUT_DIR = os.path.join(BASE_DIR, MIND_DATA_SOURCE_DIR, \"train/\")\n",
    "ORIGINAL_TEST_INPUT_DIR = os.path.join(BASE_DIR, MIND_DATA_SOURCE_DIR, \"test/\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198110b-5927-4425-920e-b715003138ba",
   "metadata": {
    "id": "e198110b-5927-4425-920e-b715003138ba"
   },
   "source": [
    "### Vowpal wabbit\n",
    "Vowpal wabbit (vw) je extrémně rychlá implementace logistické regrese napsaná v c++. Má celou řadu užitečných vlastností, díky kterým se osvědčila v produkčních prostředích nejen Seznamu.\n",
    "\n",
    "Pro účely tohoto workshopu budeme využívat [sklearnový wrapper](https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/reference/vowpalwabbit.sklearn.html), abychom mohli s vw jednoduše interagovat v rámcí notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbd3a6-c9fe-4445-867e-17e9edede911",
   "metadata": {
    "id": "84cbd3a6-c9fe-4445-867e-17e9edede911"
   },
   "outputs": [],
   "source": [
    "!pip install vowpalwabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459e013-112d-4219-a39c-ad073b8143eb",
   "metadata": {
    "id": "b459e013-112d-4219-a39c-ad073b8143eb"
   },
   "source": [
    " # Připrava datasetu\n",
    "Pro trénování a vyhodnocení modelu potřebujeme tři typy datasetů:\n",
    " - trénovací dataset: slouží přímo k vytvoření modelu \n",
    " - validační dataset: slouží k porovnání více modelů mezi sebou např. pro vyhodnocení optimálních hyper parametrů\n",
    " - testovací dataset: slouží pro odhad výkonu modelu v produkci\n",
    "\n",
    "Více se lze dozvědet v následujícím [článku](https://machinelearningmastery.com/difference-test-validation-datasets/).\n",
    "\n",
    "Pro účely workshopu jsme zvolili menší MIND dataset, který bohužel obsahuje pouze trénovací a testovací dataset, jeden nám tedy chybí a z tohoto důvodu jsme se rozhodli rozdělit testovací dataset na dvě poloviny a první využít jako validační dataset a druhý jako testovací dataset, což není standardní (měli bychom dělit trénovací dataset), ale vzhledem k výrazným rozdílum mezi trénovacím a testovacím datasetem nám to umožní lépe modelovat data v rámci našeho cvičení.\n",
    "\n",
    "Formát našeho datasetu bude následující:\n",
    " - historie přečtených článku uživatele\n",
    " - historie kategorií, do kterých spadali články z uživatelovi historie\n",
    " - historie subkategorií, do kterých spadali články z uživatelovi historie\n",
    " - historie titulků, které měli články z uživatelovi historie\n",
    " - predikování článek a nebo také imprese\n",
    " - kategorie imprese\n",
    " - subktegorie imprese\n",
    " - titulek imprese\n",
    " - informace, zda-li uživatel na daný článek kliknul\n",
    "\n",
    "Nejprve vytvoříme dataset pomocí knihovny pandas a funkce `prepare_dataset_pd`. Následně data transformuje do [formátu vstupních dat](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format), jež vyžaduje vw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93c7cd-1666-40c0-934b-b07bbc6e191b",
   "metadata": {
    "id": "8c93c7cd-1666-40c0-934b-b07bbc6e191b"
   },
   "outputs": [],
   "source": [
    "# import necessary functionality\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "from vowpalwabbit.sklearn import VWClassifier, VW\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction. _stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a230be-6af8-4b06-ba7f-0a673915a190",
   "metadata": {
    "id": "92a230be-6af8-4b06-ba7f-0a673915a190"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def get_vocabulary(news, min_occ = 10):\n",
    "    word_occ = news.title.map(preprocess_title).str.split(\" \").explode().value_counts()\n",
    "    vocabulary = set(word_occ[word_occ > min_occ].index.tolist()) - ENGLISH_STOP_WORDS\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "def preprocess_title(title, vocabulary=None):\n",
    "    words = set(re.findall('\\w{3,}', title.lower()))\n",
    "    if vocabulary:\n",
    "        return ' '.join(words & vocabulary)\n",
    "    else:\n",
    "        return ' '.join(words)\n",
    "\n",
    "\n",
    "def prepare_dataset_pd(behaviors,\n",
    "                       news,\n",
    "                       only_category=None,\n",
    "                       shuffle=False,\n",
    "                       random_seed=42,\n",
    "                       vocabulary=None):\n",
    "    news_fildered = news\n",
    "\n",
    "    if only_category is not None:\n",
    "        news_filtered = news[news.category == only_category]\n",
    "    else:\n",
    "        news_filtered = news\n",
    "    news_filtered[\"title_proc\"] = news_filtered[\"title\"].map(lambda t: preprocess_title(t, vocabulary))\n",
    "\n",
    "    behaviors_histories_only = (\n",
    "        behaviors[[\n",
    "            \"slateid\", \"history\"\n",
    "        ]].assign(history=lambda x: x[\"history\"].fillna(\"\").str.split()).\n",
    "        explode(\"history\").reset_index(drop=True).reset_index(\n",
    "            drop=False)  # trick to preserve original ordering through merge\n",
    "        .merge(\n",
    "            news_filtered[[\"category\", \"subcategory\", \"title_proc\"]],\n",
    "            left_on=\"history\",\n",
    "            right_index=True,\n",
    "            how=\"inner\",\n",
    "            sort=False,\n",
    "        ).sort_values(\"index\").drop(\"index\",\n",
    "                                    axis=1)  # restore original ordering\n",
    "        .groupby(\"slateid\", as_index=False).agg({\n",
    "            \"history\": lambda x: x.unique().tolist(),\n",
    "            \"category\": lambda x: x.unique().tolist(),\n",
    "            \"subcategory\": lambda x: x.unique().tolist(),\n",
    "            \"title_proc\": lambda x: x.map(lambda xx: xx.split()).apply(pd.Series).unstack().dropna().unique().tolist()\n",
    "        }).assign(history=lambda x: x[\"history\"].str.join(\" \"),\n",
    "                  category=lambda x: x[\"category\"].str.join(\" \"),\n",
    "                  subcategory=lambda x: x[\"subcategory\"].str.join(\" \"),\n",
    "                  title=lambda x: x[\"title_proc\"].str.join(\" \")))\n",
    "\n",
    "    # filter impressions to news-only\n",
    "    behaviors_impressions_only = (\n",
    "        behaviors[[\n",
    "            \"slateid\", \"impressions\"\n",
    "        ]].assign(impressions=lambda x: x[\"impressions\"].fillna(\"\").str.split(\n",
    "        )).explode(\"impressions\").assign(\n",
    "            impression_id=lambda x: x[\"impressions\"].str.split(\"-\").str[0]).\n",
    "        assign(click=lambda x: x[\"impressions\"].str.split(\n",
    "            \"-\").str[1].astype(int)).reset_index(drop=True).reset_index(\n",
    "                drop=False)  # trick to preserve original ordering through merge\n",
    "        .merge(news_filtered[[\"category\", \"subcategory\", \"title_proc\"]],\n",
    "               left_on=\"impression_id\",\n",
    "               right_index=True,\n",
    "               how=\"inner\",\n",
    "               sort=False).sort_values(\"index\").drop([\"index\", \"impressions\"],\n",
    "                                                     axis=1).rename(columns={\"title_proc\": \"title\"}))\n",
    "\n",
    "    df = behaviors_impressions_only.merge(\n",
    "        behaviors_histories_only,\n",
    "        on=\"slateid\",\n",
    "        how=\"inner\",\n",
    "        suffixes=[\"_i\", \"\"]).assign(history=lambda x: x.history.fillna(\" \"))\n",
    "\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1.0, random_state=random_seed)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dataset_vw(\n",
    "    df,\n",
    "    output_path,\n",
    "    cls_weights=None,\n",
    "    include_categories=False,\n",
    "    include_subcategories=False,\n",
    "    include_title=False\n",
    "):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            # write label and sample weight\n",
    "            sample_weight = f\"{cls_weights[row.click]:0.3f}\" if cls_weights else '1'\n",
    "            f.write(f\"{1 if int(row.click) else -1} {sample_weight} \")\n",
    "            # write user history\n",
    "            f.write(\n",
    "                f\"|h {row.history} |i {row.impression_id}\")\n",
    "\n",
    "            if include_categories:\n",
    "                f.write(f\"|c {row.category} |j {row.category_i}\")\n",
    "\n",
    "            if include_subcategories:\n",
    "                f.write(f\"|k {row.subcategory} |l {row.subcategory_i}\")\n",
    "\n",
    "            if include_title:\n",
    "                f.write(\n",
    "                    f\"|t {row.title} |o {row.title_i}\"\n",
    "                )\n",
    "\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9228b0c-6d7e-4513-8a8e-211b5f2169fc",
   "metadata": {
    "id": "d9228b0c-6d7e-4513-8a8e-211b5f2169fc"
   },
   "outputs": [],
   "source": [
    "behaviors_train = pd.read_csv(\n",
    "    os.path.join(ORIGINAL_TRAIN_INPUT_DIR, \"behaviors.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    names=[\"slateid\", \"userid\", \"time\", \"history\", \"impressions\"]\n",
    ").sample(frac=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab7b5f-e770-4971-80e4-64b678a77140",
   "metadata": {
    "id": "89ab7b5f-e770-4971-80e4-64b678a77140"
   },
   "outputs": [],
   "source": [
    "behaviors_val_test = pd.read_csv(\n",
    "    os.path.join(ORIGINAL_TEST_INPUT_DIR, \"behaviors.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    names=[\"slateid\", \"userid\", \"time\", \"history\", \"impressions\"]\n",
    ").sample(frac=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03f720-7f22-493b-93a8-ec4f603a63a4",
   "metadata": {
    "id": "ff03f720-7f22-493b-93a8-ec4f603a63a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_train = pd.read_csv(\n",
    "    os.path.join(ORIGINAL_TRAIN_INPUT_DIR, \"news.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    names=[\"newsid\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    ").set_index(\"newsid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nD9V027kuYe3",
   "metadata": {
    "id": "nD9V027kuYe3"
   },
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(news_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff64e3f-ae84-4e5a-8a1d-7be3294529bd",
   "metadata": {
    "id": "6ff64e3f-ae84-4e5a-8a1d-7be3294529bd"
   },
   "outputs": [],
   "source": [
    "news_val_test = pd.read_csv(\n",
    "    os.path.join(ORIGINAL_TEST_INPUT_DIR, \"news.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    names=[\"newsid\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    ").set_index(\"newsid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4569079-8d97-4a91-82e5-1af1490bbc62",
   "metadata": {
    "id": "e4569079-8d97-4a91-82e5-1af1490bbc62"
   },
   "outputs": [],
   "source": [
    "behaviors_train_ex = prepare_dataset_pd(\n",
    "    behaviors_train,\n",
    "    news_train,\n",
    "    shuffle=True,\n",
    "    vocabulary=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c61fc-a728-4336-8b2c-abbb20ddffdb",
   "metadata": {
    "id": "513c61fc-a728-4336-8b2c-abbb20ddffdb"
   },
   "outputs": [],
   "source": [
    "behaviors_test, behaviors_val = train_test_split(\n",
    "    behaviors_val_test,\n",
    "    test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c32c90-d0e1-4e01-862a-b50db237b118",
   "metadata": {
    "id": "80c32c90-d0e1-4e01-862a-b50db237b118"
   },
   "outputs": [],
   "source": [
    "behaviors_val_ex = prepare_dataset_pd(\n",
    "    behaviors_val,\n",
    "    news_val_test,\n",
    "    vocabulary=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad08f8-3c2e-462b-a7f4-ab473d049b3f",
   "metadata": {
    "id": "91ad08f8-3c2e-462b-a7f4-ab473d049b3f"
   },
   "outputs": [],
   "source": [
    "behaviors_test_ex = prepare_dataset_pd(\n",
    "    behaviors_test,\n",
    "    news_val_test,\n",
    "    vocabulary=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260d978-50e1-4892-8013-7dfac3a4019b",
   "metadata": {
    "id": "4260d978-50e1-4892-8013-7dfac3a4019b"
   },
   "source": [
    " ## Jak pracovat s nevyváženým datasetem?\n",
    "Náš dataset je silně nevyvážený ve prospěch negativních příkladu, které více než 10x prevyšují pozitivní příklady, jak takovouto situaci můžeme řešit:\n",
    " - oversampling/undersampling minoritní/majoritní třídy\n",
    " - vážením klasifikačních tříd\n",
    " - vážením trénovacích příkladu\n",
    "\n",
    "VW podporuje [poslední možnost řešení](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format#simple).\n",
    "\n",
    "V následujících buňkách vypočteme váhy pozitivních a negativních příkladu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a646348-b49a-4117-a72a-1df64477398b",
   "metadata": {
    "id": "2a646348-b49a-4117-a72a-1df64477398b"
   },
   "outputs": [],
   "source": [
    "# compute positive & negative example counts\n",
    "neg_count, pos_count = behaviors_train_ex.click.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01bbdc-8c5e-41d4-9e06-174056657822",
   "metadata": {
    "id": "5a01bbdc-8c5e-41d4-9e06-174056657822"
   },
   "outputs": [],
   "source": [
    "cls_weights = {\n",
    "    0:  (1 / neg_count) * ((neg_count + pos_count) / 2.0),\n",
    "    1:  (1 / pos_count) * ((neg_count + pos_count) / 2.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e794f44-0ffe-4be1-b472-30a5d2f243dc",
   "metadata": {
    "id": "8e794f44-0ffe-4be1-b472-30a5d2f243dc"
   },
   "outputs": [],
   "source": [
    "prepare_dataset_vw(\n",
    "    behaviors_train_ex,\n",
    "    \"/tmp/vw_train_data_all.dat\",\n",
    "    include_categories=True,\n",
    "    include_subcategories=True,\n",
    "    include_title=True,\n",
    "    cls_weights=cls_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed37c27-1427-493a-8c43-9e663ec5b10c",
   "metadata": {
    "id": "fed37c27-1427-493a-8c43-9e663ec5b10c"
   },
   "outputs": [],
   "source": [
    "prepare_dataset_vw(\n",
    "    behaviors_val_ex,\n",
    "    \"/tmp/vw_val_data_all.dat\",\n",
    "    include_categories=True,\n",
    "    include_subcategories=True,\n",
    "    include_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c41f4-1a15-403d-a554-c3327249d973",
   "metadata": {
    "id": "951c41f4-1a15-403d-a554-c3327249d973"
   },
   "outputs": [],
   "source": [
    "prepare_dataset_vw(\n",
    "    behaviors_test_ex,\n",
    "    \"/tmp/vw_test_data_all.dat\",\n",
    "    include_categories=True,\n",
    "    include_subcategories=True,\n",
    "    include_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea421a-a9ea-4ce0-84f6-763abdce0565",
   "metadata": {
    "id": "f5ea421a-a9ea-4ce0-84f6-763abdce0565"
   },
   "source": [
    "# Kontrola vytvorenych datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ff861-0ad8-4e60-87b8-1ece4089491e",
   "metadata": {
    "id": "9a4ff861-0ad8-4e60-87b8-1ece4089491e"
   },
   "outputs": [],
   "source": [
    "!du -sh \"/tmp/vw_train_data_all.dat\"\n",
    "!wc -l \"/tmp/vw_train_data_all.dat\"\n",
    "!head -n 5 \"/tmp/vw_train_data_all.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab61091-28ce-4435-a57e-8e3db41e7f00",
   "metadata": {
    "id": "9ab61091-28ce-4435-a57e-8e3db41e7f00"
   },
   "outputs": [],
   "source": [
    "!du -sh \"/tmp/vw_val_data_all.dat\"\n",
    "!wc -l \"/tmp/vw_val_data_all.dat\"\n",
    "!head -n 5 \"/tmp/vw_val_data_all.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490cdb-86d7-4baa-be93-07a63eb6dada",
   "metadata": {
    "id": "eb490cdb-86d7-4baa-be93-07a63eb6dada"
   },
   "outputs": [],
   "source": [
    "!du -sh \"/tmp/vw_test_data_all.dat\"\n",
    "!wc -l \"/tmp/vw_test_data_all.dat\"\n",
    "!head -n 5 \"/tmp/vw_test_data_all.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3b6bd-9e0a-4873-b32e-0393d84a1a05",
   "metadata": {
    "id": "a4b3b6bd-9e0a-4873-b32e-0393d84a1a05"
   },
   "source": [
    "# Trénování modelu\n",
    "\n",
    "Pro experimentování budou důležité následující základní parametry:\n",
    " - convert_to_vw: parametr určující zda-li se má provést konverze vstupu do formátu vw\n",
    " - convert_labels: transformace anotaci z rozsahu [0,1] do rozsahu [-1,1]\n",
    " - loss_function: loss funkce - v našem případě to bude hodnota 'logistic'\n",
    " - link: opět hodnota 'logistic' - zajistí, že budeme predikovat hodnoty z rozsahu [0, 1] - tedy z [bernoulliho distribuce](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n",
    " - quiet: specifikuje, zda-li chceme na výstupu debug informace \n",
    " - keep: omezuje množství používaných signálu z datasetu\n",
    " - passes: specifikuje množství průchodu datasetem při trénování\n",
    " - bit_precision: definuje velikost hashovacího prostoru\n",
    " - holdout_off: specifikuje, zda-li použít část validačních dat pro cross validace\n",
    " - kill_cache: specifikuje, zda-li chceme pokaždé začít s prazdnou cache\n",
    " - data: specifikuje cestu k trénovacím datům\n",
    " - cache_file: cesta ke cache soubor\n",
    " - random_seed: seed pro inicializace modelu, zajistí reprodukovatelnost\n",
    " - hash_seed: seed pro hashování signalu, zajistí reprodukovatelnost\n",
    "\n",
    "V rámcí workshopu si nejprve demonstrujeme jak natrénovat základní popularity model a následně si sami vyzkoušíte modelování a budete se pokoušet dosáhnout co možná nejlepšího skóré.\n",
    "\n",
    "## Metriky\n",
    "Stanovení vhodných metrik pro vyhodnocení modelovací úlohy je kritické.\n",
    "\n",
    "V oblasti doporučování se využíváji metriky zaměřené na zhodnocení celého doporučovaného slatu (aneb většinou prezentujeme uživateli více než jeden konkrétní objekt):\n",
    " - [NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)\n",
    " - [recall@k](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54)\n",
    " - [precission@k](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54)\n",
    " - [novelty](https://medium.com/@ayanglaishram/novelty-in-recommender-system-1a3da04e3b1f)\n",
    " - ...\n",
    "\n",
    "V rámci workshopu budeme pracovat s metrikami zaměřenými na konkrétní článek, které budou zhodnocovat jak dobře jsme odhadli relativní skóre mezi články (pří doporučování článku je uživateli předkládáme od největšího skóre):\n",
    "  - [AUC](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)\n",
    "  - [Log loss](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb2df6-0642-40d6-a407-b7e4bfb75a0c",
   "metadata": {
    "id": "b8bb2df6-0642-40d6-a407-b7e4bfb75a0c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define variable for storing results\n",
    "MODEL_RESULTS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fbcbe-33d4-420f-8058-bc5ed246522a",
   "metadata": {
    "id": "ab3fbcbe-33d4-420f-8058-bc5ed246522a"
   },
   "outputs": [],
   "source": [
    "# define common parameters for vw training\n",
    "base_params = {\n",
    "    \"convert_to_vw\": False,\n",
    "    \"convert_labels\": False,\n",
    "    \"loss_function\": \"logistic\",\n",
    "    \"link\": \"logistic\",\n",
    "    \"quiet\": True,\n",
    "    \"keep\": \"i\",\n",
    "    \"passes\": 1,\n",
    "    \"bit_precision\": 22,\n",
    "    \"holdout_off\": True,\n",
    "    \"kill_cache\": True,\n",
    "    \"data\": \"/tmp/vw_train_data_all.dat\",\n",
    "    \"cache_file\": \"/tmp/vw_cache.out\",\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"hash_seed\": RANDOM_SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdd677-00cf-476b-ac5b-496997e4f239",
   "metadata": {
    "id": "f9fdd677-00cf-476b-ac5b-496997e4f239"
   },
   "outputs": [],
   "source": [
    "# load validation data for vw evaluation\n",
    "with open(\"/tmp/vw_val_data_all.dat\", \"r\") as f:\n",
    "    val_data_wv_raw_all = f.read()\n",
    "\n",
    "val_data_wv_all = [r for r in val_data_wv_raw_all.split(\"\\n\") if r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609a88e-a0a4-40f0-b2ba-4763c0f4aba9",
   "metadata": {
    "id": "f609a88e-a0a4-40f0-b2ba-4763c0f4aba9"
   },
   "outputs": [],
   "source": [
    "def train_eval_vw(base_params, params, vw_val_data, val_data_df):\n",
    "    global MODEL_RESULTS\n",
    "\n",
    "    for param in tqdm(params):\n",
    "        result = {}\n",
    "        a_params = {**base_params, **param}\n",
    "        vw_classifier = VWClassifier(**a_params)\n",
    "        vw_classifier.fit()\n",
    "        evaluation = evaluate_model(vw_classifier, val_data_df, vw_val_data)\n",
    "\n",
    "        MODEL_RESULTS.append({\n",
    "            \"all_params\": a_params,\n",
    "            \"params\": param,\n",
    "            \"model\": vw_classifier,\n",
    "            **evaluation\n",
    "        })\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_df, vw_data):\n",
    "    result = {}\n",
    "    result[\"predictions\"] = model.predict_proba(vw_data)\n",
    "    result[\"labels\"] = data_df.click.tolist()\n",
    "    result[\"auc\"] = metrics.roc_auc_score(\n",
    "       data_df.click.tolist(),\n",
    "       result[\"predictions\"][:, 1]\n",
    "    )\n",
    "    result[\"log_loss\"] = metrics.log_loss(\n",
    "        data_df.click.tolist(),\n",
    "        result[\"predictions\"][:, 1]\n",
    "    )\n",
    "    result[\"roc_curve\"] = metrics.roc_curve(\n",
    "        data_df.click.astype(int).tolist(),\n",
    "        result[\"predictions\"][:, 1]\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def visualize_evaluation(result):\n",
    "    print(f\"Model configuration: {result['params']}\")\n",
    "    print(f\"Log loss: {result['log_loss']}\")\n",
    "\n",
    "    plt.plot(result[\"roc_curve\"][0], result[\"roc_curve\"][1])\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"test AUC = %f\" % (result['auc']))\n",
    "    plt.axis([-0.05, 1.05, -0.05, 1.05])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    y_pred_class = result[\"predictions\"][:, 1] > 0.5\n",
    "    cm = metrics.confusion_matrix(result[\"labels\"], y_pred_class)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "\n",
    "def pick_best_result():\n",
    "    global MODEL_RESULTS\n",
    "\n",
    "    if not MODEL_RESULTS:\n",
    "        return None\n",
    "\n",
    "    best_result = MODEL_RESULTS[0]\n",
    "\n",
    "    for r in MODEL_RESULTS[1:]:\n",
    "        if r[\"auc\"] > best_result[\"auc\"]:\n",
    "            best_result = r\n",
    "    \n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04237905-c044-4a91-8913-80d7eb70c499",
   "metadata": {
    "id": "04237905-c044-4a91-8913-80d7eb70c499"
   },
   "outputs": [],
   "source": [
    "train_eval_vw(base_params, [{}], val_data_wv_all, behaviors_val_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d39c13-7003-4897-a693-75ebe8889405",
   "metadata": {
    "id": "c3d39c13-7003-4897-a693-75ebe8889405"
   },
   "outputs": [],
   "source": [
    "visualize_evaluation(MODEL_RESULTS[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IfIoz_gNqadQ",
   "metadata": {
    "id": "IfIoz_gNqadQ"
   },
   "source": [
    "# Dokážete natrénovat lepší model?\n",
    "Není to tak jednoduché jak by se zdálo! Zmíněný popularity model představuje docela silnou baseline a není jednoduché ji překonat.\n",
    "\n",
    "Tento dataset obsahuje skutečná produkční data a reálné problémy, se kterými se potkáte v produkčním prostředí. Konkrétně v oblasti doporučování zpravodajských článku narazíte na tzv. item cold-start problém, více si o tomto fenoménu můžete nastudovat [tady](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)#New_item).\n",
    "\n",
    "K item cold-startu dochází v důsledků toho, že každý den vznikají nové unikatní članky (zprávy), které ještě ani žádný uživatel neviděl a tím pádem je neviděl ani váš model v rámci trénovacích dat. Tento problém lze v produkčním systému mitigovat např. pomoci využítí techniky [contextového bandity](https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/tutorials/python_Contextual_bandits_and_Vowpal_Wabbit.html#contextual-bandits). My se však budeme zaměřovat na jiný typ řešení a sice přes vhodnou reprezentaci doporučovaných článku, přičemž dataset obsahuje následující metadata o článcích:\n",
    " - titulek článku(t) a imprese(o)\n",
    " - kategorie článku(c) a imprese(j)\n",
    " - subcategorie článku(k) a imprese(l)\n",
    "\n",
    "Pro účely experimentování s výkonem modelu se můžou hodit tyto parametry:\n",
    "  - passes: určuje kolik průchodu se má využít pro trénovaní\n",
    "  - keep: určuje jaké signály se mají použít pro trénování, tzn. umožnuje využít pouze subset signálu z datasetu\n",
    "  - interactions: umožnuje zkombinovat více signálu pro zvýšení komplexity modelu\n",
    "  - quadratic: podobně jako parametr 'interactions', ale pouze kvadratické kombinace\n",
    "  - cubic: podobně jako parametr 'quadratic', ale pouze kubické kombinace\n",
    "  - bit precission: určuje velikost prostoru všech signálu\n",
    "  - l2: zapne l2 regularizaci\n",
    "  - l1: zapne l1 regularizaci\n",
    "  - learning_rate: nastaví koeficient ovlivňující velikost gradientů\n",
    "  - ignore_linear: odstranění jednoduché kombinace signálu\n",
    "\n",
    "**!!!Pokud experimentujete s novým signálem a jeho kombinací, nezapomeňte ho úvest taky v rámci parametru 'keep'!!!**\n",
    "\n",
    "[Hyperparametr optimalizace](https://en.wikipedia.org/wiki/Hyperparameter_optimization) je process, při kterém se snažíme minimalizovat chybu na validačním datasetu, většinou je plně automatizovaný. V případě vw lze využít [vw-hypersearch](https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/utl/vw-hypersearch). Sklearn taktéž nabízí funkcionalitu pro hledání [optimalizaci hyperparametru](https://scikit-learn.org/stable/modules/grid_search.html). V rámci workshopu si tento process vyzkoušíme manuálně.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O3wky2am_1rE",
   "metadata": {
    "id": "O3wky2am_1rE"
   },
   "outputs": [],
   "source": [
    "## example of feature interactions\n",
    "# train_eval_vw(base_params, [{\n",
    "#     \"keep\": \"hi\",\n",
    "#     \"interactions\": \"hi\",\n",
    "#     \"passes\": 2\n",
    "# }], val_data_wv_all, behaviors_val_ex)\n",
    "\n",
    "# visualize_evaluation(MODEL_RESULTS[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yqns4qrqDwVc",
   "metadata": {
    "id": "Yqns4qrqDwVc"
   },
   "outputs": [],
   "source": [
    "train_eval_vw(base_params, [{\n",
    "    \"keep\": \"hi\",\n",
    "    \"interactions\": \"hi\",\n",
    "    \"passes\": 2\n",
    "}], val_data_wv_all, behaviors_val_ex)\n",
    "\n",
    "visualize_evaluation(MODEL_RESULTS[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695dc0e-2cfd-415b-8f46-4719c34533c6",
   "metadata": {
    "id": "6695dc0e-2cfd-415b-8f46-4719c34533c6"
   },
   "source": [
    "# Finalni evaluace modelu\n",
    "Pro odhad výkonu modelu v produkci využijeme testovací dataset, který využijeme pouze jednou pro finálni evaluaci modelu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffc51a-55d5-4161-93e4-eae58e5fd0ab",
   "metadata": {
    "id": "50ffc51a-55d5-4161-93e4-eae58e5fd0ab"
   },
   "outputs": [],
   "source": [
    "with open(\"/tmp/vw_test_data_all.dat\", \"r\") as f:\n",
    "    test_data_wv_raw_all = f.read()\n",
    "\n",
    "test_data_wv_all = [r for r in test_data_wv_raw_all.split(\"\\n\") if r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PTp0G_nhZLfH",
   "metadata": {
    "id": "PTp0G_nhZLfH"
   },
   "outputs": [],
   "source": [
    "# uncomment in order to attempt final evaluation\n",
    "# best_result = pick_best_result()\n",
    "# test_evaluation = evaluate_model(best_result[\"model\"], behaviors_test_ex, test_data_wv_all)\n",
    "# visualize_evaluation({**best_result, **test_evaluation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AKppENaDvb-_",
   "metadata": {
    "id": "AKppENaDvb-_"
   },
   "source": [
    "# Závěrem\n",
    "Doufáme, že Vás modelování bavilo. Pokud byste chtěli Vaše modely srovnat se světovou špičkou, bude potřeba natrénovat model na [plné datové sadě](https://msnews.github.io/#getting-start).\n",
    "\n",
    "Pokud by Vás zajímaly modely a signály, které na této datové sadě uspěly, tak lze nalézt informace [tady](https://paperswithcode.com/sota/news-recommendation-on-mind), [tady](https://msnews.github.io/assets/doc/ACL2020_MIND.pdf) a [tady](https://msnews.github.io/assets/doc/1.pdf).\n",
    "\n",
    "## Na co jsme zapoměli?\n",
    "V rámci modelace jsme nezkoumali [fungování modelu](https://medium.com/ing-blog/model-explainability-how-to-choose-the-right-tool-6c5eabd1a46a) (konkrétně například významovost jednotlivých vah) a ani jsme se nedívali na vyprodukované predikce. Pochopení fungování modelu je v praxi enormně důležité a typicky se volí model, jemuž jsme schopni poruzumět oproti modelu, který sice na metrikách funguje brilantně, ale není zřéjmě proč.\n",
    "\n",
    "V případě vw není úplně jednoduché k této informaci dospět a je potřeba vyvinout trochu snahy, je potřeba využít [audit](https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/tutorials/cmd_linear_regression.html) parametr. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
